From b049eda89ec1245a33c22f5d114f2d0396d5be65 Mon Sep 17 00:00:00 2001
From: Michal Kubecek <mkubecek@suse.cz>
Date: Mon, 21 Aug 2023 19:54:57 +0200
Subject: [PATCH] vmmon: use get_user_pages to get page PFN

As a side effect of mainline commit 0d940a9b270b ("mm/pgtable: allow
pte_offset_map[_lock]() to fail") in 6.5-rc1, __pte_offset_map(), called by
pte_offset_map(), is no longer exported.

As this function is only used to get PFN from a virtual address, is is more
appropriate (and reliable) to use get_user_pages infrastructure instead.

Note: this is an experimental solution, more research will be needed to
indentify the most appropriate get_user_pages_*() function and flags.
---
 vmmon-only/include/pgtbl.h | 23 +++++++++++++++++++++++
 1 file changed, 23 insertions(+)

diff --git a/vmmon-only/include/pgtbl.h b/vmmon-only/include/pgtbl.h
index 0935e090..2334e290 100644
--- a/vmmon-only/include/pgtbl.h
+++ b/vmmon-only/include/pgtbl.h
@@ -25,6 +25,7 @@
 #include "compat_pgtable.h"
 #include "compat_spinlock.h"
 #include "compat_page.h"
+#include "compat_version.h"
 
 
 /*
@@ -45,6 +46,8 @@
  *-----------------------------------------------------------------------------
  */
 
+#if COMPAT_LINUX_VERSION_CHECK_LT(6, 5, 0)
+
 static INLINE MPN
 PgtblVa2MPNLocked(struct mm_struct *mm, // IN: Mm structure of a process
                   VA addr)              // IN: Address in the virtual address
@@ -139,4 +142,24 @@ PgtblVa2MPN(VA addr)  // IN
    return mpn;
 }
 
+#else /* COMPAT_LINUX_VERSION_CHECK_LT(6, 5, 0) */
+
+static INLINE MPN
+PgtblVa2MPN(VA addr)  // IN
+{
+   struct page *page;
+   int npages;
+   MPN mpn;
+
+   npages = get_user_pages_unlocked(addr, 1, &page, FOLL_HWPOISON);
+   if (npages != 1)
+	   return INVALID_MPN;
+   mpn = page_to_pfn(page);
+   put_page(page);
+
+   return mpn;
+}
+
+#endif /* COMPAT_LINUX_VERSION_CHECK_LT(6, 5, 0) */
+
 #endif /* __PGTBL_H__ */
